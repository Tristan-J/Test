{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/cat-dog\"\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def flip_lr(x): \n",
    "# horizontal flip transformation\n",
    "    if random.random()>0.5:\n",
    "        x = np.fliplr(x).copy()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from skimage import io, img_as_float32\n",
    "import os\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, data_dir, is_train=False, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.data_dir = os.path.join(data_dir, \"train\")\n",
    "        else:\n",
    "            self.data_dir = os.path.join(data_dir, \"test\")\n",
    "        self.img_ids = os.listdir(self.data_dir)\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_p = os.path.join(self.data_dir, img_id)\n",
    "        img = img_as_float32(io.imread(img_p)).transpose((2,0,1))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        out = {}\n",
    "        out['name'] = img_id\n",
    "        if self.is_train:\n",
    "            out['img'] = img\n",
    "            out['label'] = 0 if img_id.split(\"_\")[1]=='cat' else 1\n",
    "        else:\n",
    "            out['img'] = img\n",
    "            out['label'] = 0 if img_id.split(\"_\")[1]=='cat' else 1\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flickr_dog_000013.jpg', 'flickr_cat_000054.jpg', 'flickr_dog_000044.jpg', 'flickr_dog_000002.jpg']\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = CatDogDataset(data_dir, is_train=True, transform=flip_lr)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "for x_i, x in enumerate(dataloader):\n",
    "    print(x['name'])\n",
    "    print(x['label'])\n",
    "    print(x['img'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.6950, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "decoder_1 step0:\n",
      "0.weight tensor([[[[ 0.2185, -0.0138,  0.1966],\n",
      "          [ 0.1699,  0.0583,  0.1697],\n",
      "          [ 0.1267,  0.2172, -0.0634]],\n",
      "\n",
      "         [[ 0.1925,  0.2151, -0.0301],\n",
      "          [ 0.2544, -0.0651,  0.2653],\n",
      "          [ 0.0013,  0.0618, -0.0176]],\n",
      "\n",
      "         [[ 0.1498,  0.0837, -0.0042],\n",
      "          [ 0.0376,  0.2251, -0.2379],\n",
      "          [ 0.1500, -0.0341,  0.1122]],\n",
      "\n",
      "         [[ 0.1791,  0.1259, -0.0328],\n",
      "          [-0.0073, -0.0265,  0.1859],\n",
      "          [-0.0341,  0.2337,  0.2162]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376, -0.1429, -0.1286],\n",
      "          [ 0.1939,  0.1836,  0.1059],\n",
      "          [-0.0140, -0.0231,  0.1421]],\n",
      "\n",
      "         [[-0.0819, -0.1367, -0.0840],\n",
      "          [ 0.2254,  0.1810,  0.1778],\n",
      "          [ 0.2321,  0.1536,  0.0306]],\n",
      "\n",
      "         [[-0.1590,  0.1090,  0.1535],\n",
      "          [-0.1991,  0.0952, -0.1795],\n",
      "          [-0.1225,  0.1179, -0.0391]],\n",
      "\n",
      "         [[-0.0534,  0.1334,  0.0824],\n",
      "          [-0.0289,  0.0487,  0.2333],\n",
      "          [ 0.2163, -0.0169,  0.0932]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0538,  0.0346,  0.0006],\n",
      "          [-0.0039,  0.2031, -0.0297],\n",
      "          [ 0.0732, -0.0374,  0.0723]],\n",
      "\n",
      "         [[ 0.0216,  0.0673,  0.1893],\n",
      "          [ 0.0462,  0.1881,  0.0373],\n",
      "          [ 0.2199,  0.0209,  0.0355]],\n",
      "\n",
      "         [[ 0.0207,  0.1111,  0.1250],\n",
      "          [-0.2138, -0.2014, -0.0206],\n",
      "          [ 0.0521, -0.0611,  0.1676]],\n",
      "\n",
      "         [[ 0.1833,  0.1271,  0.2644],\n",
      "          [ 0.2164,  0.0629,  0.0293],\n",
      "          [ 0.2390, -0.2509,  0.0179]]]], device='cuda:0')\n",
      "0.bias tensor([0.2328, 0.0305, 0.1513], device='cuda:0')\n",
      "decoder_1 step1:\n",
      "0.weight tensor([[[[ 0.2855,  0.0532,  0.2636],\n",
      "          [ 0.2369,  0.1253,  0.2367],\n",
      "          [ 0.1937,  0.2842,  0.0036]],\n",
      "\n",
      "         [[ 0.2595,  0.2821, -0.0971],\n",
      "          [ 0.3214,  0.0019,  0.3323],\n",
      "          [ 0.0683,  0.1288,  0.0494]],\n",
      "\n",
      "         [[ 0.2168,  0.1507, -0.0712],\n",
      "          [ 0.1045,  0.2921, -0.3049],\n",
      "          [ 0.2169,  0.0329,  0.1791]],\n",
      "\n",
      "         [[ 0.2461,  0.1930,  0.0342],\n",
      "          [ 0.0597,  0.0405,  0.2529],\n",
      "          [ 0.0329,  0.3007,  0.2832]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376, -0.1429, -0.1286],\n",
      "          [ 0.2609,  0.2506,  0.1729],\n",
      "          [-0.0810,  0.0439,  0.2091]],\n",
      "\n",
      "         [[-0.0819, -0.1367, -0.0840],\n",
      "          [ 0.2924,  0.2480,  0.2448],\n",
      "          [ 0.2991,  0.2206,  0.0976]],\n",
      "\n",
      "         [[-0.1590,  0.1090,  0.1535],\n",
      "          [-0.2661,  0.0952, -0.2465],\n",
      "          [-0.1895,  0.1849,  0.0279]],\n",
      "\n",
      "         [[-0.0534,  0.1334,  0.0824],\n",
      "          [ 0.0381,  0.1157,  0.3003],\n",
      "          [ 0.2832,  0.0501,  0.1602]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1208,  0.1016,  0.0676],\n",
      "          [-0.0709,  0.2701,  0.0373],\n",
      "          [ 0.1402, -0.1044,  0.1393]],\n",
      "\n",
      "         [[ 0.0886,  0.1343,  0.2563],\n",
      "          [ 0.1131,  0.2551,  0.1043],\n",
      "          [ 0.2869, -0.0461,  0.1025]],\n",
      "\n",
      "         [[-0.0463,  0.1781,  0.1919],\n",
      "          [-0.2807, -0.2683,  0.0464],\n",
      "          [-0.0149, -0.1281,  0.2346]],\n",
      "\n",
      "         [[ 0.2503,  0.1941,  0.3314],\n",
      "          [ 0.2834,  0.1297,  0.0963],\n",
      "          [ 0.3060, -0.3179,  0.0849]]]], device='cuda:0')\n",
      "0.bias tensor([0.2998, 0.0975, 0.2183], device='cuda:0')\n",
      "decoder_1 step2:\n",
      "0.weight tensor([[[[ 0.3373,  0.1050,  0.3154],\n",
      "          [ 0.2887,  0.1771,  0.2885],\n",
      "          [ 0.2455,  0.3359,  0.0554]],\n",
      "\n",
      "         [[ 0.3113,  0.3339, -0.1489],\n",
      "          [ 0.3732,  0.0537,  0.3841],\n",
      "          [ 0.1201,  0.1806,  0.1012]],\n",
      "\n",
      "         [[ 0.2686,  0.2025, -0.1230],\n",
      "          [ 0.1562,  0.3439, -0.3567],\n",
      "          [ 0.2687,  0.0847,  0.2308]],\n",
      "\n",
      "         [[ 0.2979,  0.2447,  0.0860],\n",
      "          [ 0.1115,  0.0923,  0.3047],\n",
      "          [ 0.0847,  0.3525,  0.3350]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376, -0.1429, -0.1286],\n",
      "          [ 0.3127,  0.3024,  0.2247],\n",
      "          [-0.1328,  0.0957,  0.2609]],\n",
      "\n",
      "         [[-0.0819, -0.1367, -0.0840],\n",
      "          [ 0.3442,  0.2998,  0.2965],\n",
      "          [ 0.3509,  0.2724,  0.1494]],\n",
      "\n",
      "         [[-0.1590,  0.1090,  0.1535],\n",
      "          [-0.3178,  0.0952, -0.2983],\n",
      "          [-0.2412,  0.2366,  0.0797]],\n",
      "\n",
      "         [[-0.0534,  0.1334,  0.0824],\n",
      "          [ 0.0899,  0.1675,  0.3521],\n",
      "          [ 0.3350,  0.1019,  0.2120]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1726,  0.1534,  0.1194],\n",
      "          [-0.1227,  0.3219,  0.0891],\n",
      "          [ 0.1920, -0.1562,  0.1911]],\n",
      "\n",
      "         [[ 0.1404,  0.1861,  0.3081],\n",
      "          [ 0.1647,  0.3069,  0.1561],\n",
      "          [ 0.3387, -0.0979,  0.1543]],\n",
      "\n",
      "         [[-0.0981,  0.2298,  0.2436],\n",
      "          [-0.3324, -0.3201,  0.0982],\n",
      "          [-0.0666, -0.1799,  0.2864]],\n",
      "\n",
      "         [[ 0.3021,  0.2459,  0.3832],\n",
      "          [ 0.3352,  0.1814,  0.1481],\n",
      "          [ 0.3578, -0.3697,  0.1367]]]], device='cuda:0')\n",
      "0.bias tensor([0.3516, 0.1493, 0.2701], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class ClassifyCatDog(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifyCatDog, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.encoder.append(nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, stride=1, padding=1))\n",
    "        self.encoder.append(nn.ReLU())\n",
    "        self.encoder.append(nn.MaxPool2d(8, 8))\n",
    "        self.encoder.append(nn.Conv2d(4, 4, 3, stride=1, padding=1))\n",
    "        self.encoder.append(nn.ReLU())\n",
    "        self.encoder.append(nn.MaxPool2d(8, 8))\n",
    "        # Decoder 1\n",
    "        self.decoder_1 = nn.ModuleList()\n",
    "        self.decoder_1.append(nn.Conv2d(4, 3, 3, stride=1, padding=1))\n",
    "        self.decoder_1.append(nn.ReLU())\n",
    "        self.decoder_1.append(nn.MaxPool2d(4, 4))\n",
    "        # Decoder 2\n",
    "        self.decoder_2 = nn.ModuleList()\n",
    "        self.decoder_2.append(nn.Conv2d(4, 3, 3, stride=1, padding=1))\n",
    "        self.decoder_2.append(nn.ReLU())\n",
    "        self.decoder_2.append(nn.MaxPool2d(4, 4))\n",
    "        # Classifier\n",
    "        self.classifier = nn.ModuleList()\n",
    "        self.classifier.append(nn.Linear(3*2*2, 4))\n",
    "        self.classifier.append(nn.ReLU())\n",
    "        self.classifier.append(nn.Linear(4, 2))\n",
    "    def forward(self, x, d_idx):\n",
    "        # n*512*512*3\n",
    "        # Encoder\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        # Decoder\n",
    "        if d_idx == 1:\n",
    "            for layer in self.decoder_1:\n",
    "                x = layer(x)\n",
    "        elif d_idx == 2:\n",
    "            for layer in self.decoder_2:\n",
    "                x = layer(x)\n",
    "        # Classifier\n",
    "        x = x.view(-1, 3*2*2)\n",
    "        for layer in self.classifier:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "discriminator = ClassifyCatDog()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator = discriminator.cuda()\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_all = optim.Adam(discriminator.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "\n",
    "def printParam(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        print(name, param.data)\n",
    "\n",
    "for x_i, x in enumerate(dataloader):\n",
    "    imgs   = x['img']\n",
    "    labels = x['label']\n",
    "    imgs   = imgs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    y  = discriminator(imgs, x_i%2+1)\n",
    "    loss = criterion(y, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    print(loss)\n",
    "    if x_i%2+1 == 1: # path go through decoder_1\n",
    "        optimizer_all.step()\n",
    "        optimizer_all.zero_grad()\n",
    "    else: # path go through decoder_2\n",
    "        print(\"decoder_1 step0:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "        optimizer_all.step()\n",
    "#         optimizer_all.zero_grad()\n",
    "        print(\"decoder_1 step1:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "        optimizer_all.step()\n",
    "        optimizer_all.zero_grad()\n",
    "        print(\"decoder_1 step2:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "    \n",
    "    if x_i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f1a26f59cd0>\n"
     ]
    }
   ],
   "source": [
    "print(discriminator.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for x_i, x in enumerate(dataloader):\n",
    "        if x_i%10==9:\n",
    "            print(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
