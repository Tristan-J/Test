{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/cat-dog\"\n",
    "batch_size = 4\n",
    "img_edge = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def flip_lr(x): \n",
    "# horizontal flip transformation\n",
    "    if random.random()>0.5:\n",
    "        x = np.fliplr(x).copy()\n",
    "#     return torch.from_numpy(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from skimage import io, img_as_float32\n",
    "import os\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, data_dir, is_train=False, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.data_dir = os.path.join(data_dir, \"train\")\n",
    "        else:\n",
    "            self.data_dir = os.path.join(data_dir, \"test\")\n",
    "        self.img_ids = os.listdir(self.data_dir)\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_p = os.path.join(self.data_dir, img_id)\n",
    "        img = img_as_float32(io.imread(img_p)).transpose((2,0,1))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        out = {}\n",
    "        out['name'] = img_id\n",
    "        if self.is_train:\n",
    "            out['img'] = img\n",
    "            out['label'] = 0 if img_id.split(\"_\")[1]=='cat' else 1\n",
    "        else:\n",
    "            out['img'] = img\n",
    "            out['label'] = 0 if img_id.split(\"_\")[1]=='cat' else 1\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flickr_dog_000042.jpg', 'flickr_dog_000061.jpg', 'flickr_dog_000010.jpg', 'flickr_dog_000039.jpg']\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = CatDogDataset(data_dir, is_train=True, transform=flip_lr)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "for x_i, x in enumerate(dataloader):\n",
    "    print(x['name'])\n",
    "    print(x['label'])\n",
    "    print(x['img'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "decoder 1 pre:\n",
      "0.weight tensor([[[[ 0.0018,  0.1102, -0.1208],\n",
      "          [-0.1125, -0.1494, -0.0801],\n",
      "          [ 0.1488, -0.0597,  0.0584]],\n",
      "\n",
      "         [[-0.1351, -0.0158,  0.1244],\n",
      "          [ 0.0504,  0.1350, -0.0552],\n",
      "          [ 0.1050, -0.0951, -0.0045]],\n",
      "\n",
      "         [[ 0.0207, -0.0632,  0.1141],\n",
      "          [ 0.0381, -0.0514, -0.1076],\n",
      "          [ 0.1202,  0.0731,  0.0537]],\n",
      "\n",
      "         [[-0.0660,  0.1004,  0.1133],\n",
      "          [ 0.0226,  0.1333, -0.0049],\n",
      "          [ 0.0266,  0.0897, -0.0640]]],\n",
      "\n",
      "\n",
      "        [[[-0.0937,  0.0133,  0.0261],\n",
      "          [-0.1330,  0.1154, -0.1417],\n",
      "          [-0.0073,  0.1626, -0.0954]],\n",
      "\n",
      "         [[ 0.1268,  0.0268, -0.0202],\n",
      "          [-0.0229,  0.0610, -0.1383],\n",
      "          [ 0.1023, -0.0029,  0.0923]],\n",
      "\n",
      "         [[ 0.0034,  0.1171, -0.1101],\n",
      "          [ 0.0209,  0.1633,  0.0505],\n",
      "          [ 0.0991, -0.0437,  0.0201]],\n",
      "\n",
      "         [[ 0.1666,  0.0018, -0.1574],\n",
      "          [ 0.1601, -0.1250, -0.1046],\n",
      "          [-0.0721, -0.0713, -0.0866]]],\n",
      "\n",
      "\n",
      "        [[[-0.0672, -0.1270, -0.1612],\n",
      "          [-0.0646, -0.0907, -0.1281],\n",
      "          [-0.1025,  0.1493, -0.1137]],\n",
      "\n",
      "         [[-0.0214, -0.1304, -0.1417],\n",
      "          [ 0.1027,  0.0050, -0.1118],\n",
      "          [ 0.1574, -0.0549, -0.1380]],\n",
      "\n",
      "         [[-0.0186, -0.0663,  0.0893],\n",
      "          [ 0.1015,  0.0630,  0.0623],\n",
      "          [-0.1004,  0.0571, -0.0244]],\n",
      "\n",
      "         [[ 0.0534,  0.1093,  0.1246],\n",
      "          [-0.1567, -0.0188,  0.1473],\n",
      "          [ 0.0536,  0.0968, -0.0501]]]], device='cuda:0')\n",
      "0.bias tensor([ 0.0877, -0.1304, -0.1377], device='cuda:0')\n",
      "decoder 1 after:\n",
      "0.weight tensor([[[[ 0.0018,  0.1102, -0.1208],\n",
      "          [-0.1125, -0.1494, -0.0801],\n",
      "          [ 0.1488, -0.0597,  0.0584]],\n",
      "\n",
      "         [[-0.1351, -0.0158,  0.1244],\n",
      "          [ 0.0504,  0.1350, -0.0552],\n",
      "          [ 0.1050, -0.0951, -0.0045]],\n",
      "\n",
      "         [[ 0.0207, -0.0632,  0.1141],\n",
      "          [ 0.0381, -0.0514, -0.1076],\n",
      "          [ 0.1202,  0.0731,  0.0537]],\n",
      "\n",
      "         [[-0.0660,  0.1004,  0.1133],\n",
      "          [ 0.0226,  0.1333, -0.0049],\n",
      "          [ 0.0266,  0.0897, -0.0640]]],\n",
      "\n",
      "\n",
      "        [[[-0.0937,  0.0133,  0.0261],\n",
      "          [-0.1330,  0.1154, -0.1417],\n",
      "          [-0.0073,  0.1626, -0.0954]],\n",
      "\n",
      "         [[ 0.1268,  0.0268, -0.0202],\n",
      "          [-0.0229,  0.0610, -0.1383],\n",
      "          [ 0.1023, -0.0029,  0.0923]],\n",
      "\n",
      "         [[ 0.0034,  0.1171, -0.1101],\n",
      "          [ 0.0209,  0.1633,  0.0505],\n",
      "          [ 0.0991, -0.0437,  0.0201]],\n",
      "\n",
      "         [[ 0.1666,  0.0018, -0.1574],\n",
      "          [ 0.1601, -0.1250, -0.1046],\n",
      "          [-0.0721, -0.0713, -0.0866]]],\n",
      "\n",
      "\n",
      "        [[[-0.0672, -0.1270, -0.1612],\n",
      "          [-0.0646, -0.0907, -0.1281],\n",
      "          [-0.1025,  0.1493, -0.1137]],\n",
      "\n",
      "         [[-0.0214, -0.1304, -0.1417],\n",
      "          [ 0.1027,  0.0050, -0.1118],\n",
      "          [ 0.1574, -0.0549, -0.1380]],\n",
      "\n",
      "         [[-0.0186, -0.0663,  0.0893],\n",
      "          [ 0.1015,  0.0630,  0.0623],\n",
      "          [-0.1004,  0.0571, -0.0244]],\n",
      "\n",
      "         [[ 0.0534,  0.1093,  0.1246],\n",
      "          [-0.1567, -0.0188,  0.1473],\n",
      "          [ 0.0536,  0.0968, -0.0501]]]], device='cuda:0')\n",
      "0.bias tensor([ 0.0877, -0.1304, -0.1377], device='cuda:0')\n",
      "decoder 1 end.\n",
      "tensor(0.7720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "decoder 2 pre:\n",
      "0.weight tensor([[[[ 9.4249e-02,  4.0626e-02, -2.4266e-02],\n",
      "          [-1.1782e-01,  1.1601e-01,  2.1956e-01],\n",
      "          [-4.3060e-02,  3.7887e-02,  1.7997e-02]],\n",
      "\n",
      "         [[-1.5986e-01,  1.1632e-01,  4.2227e-02],\n",
      "          [-2.4475e-02, -3.8385e-05,  5.4114e-05],\n",
      "          [ 2.1866e-01, -2.6229e-02,  1.1011e-01]],\n",
      "\n",
      "         [[-2.2395e-03,  1.0147e-01,  6.9278e-02],\n",
      "          [ 1.6367e-01,  5.7355e-02, -5.7428e-02],\n",
      "          [ 1.8572e-01,  7.0400e-02,  2.2723e-01]],\n",
      "\n",
      "         [[ 1.3824e-01,  2.5139e-01,  9.5475e-02],\n",
      "          [ 1.7141e-01,  1.9503e-01,  5.3442e-04],\n",
      "          [-2.6682e-02,  2.4697e-01,  2.5612e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.9886e-02, -8.1777e-02,  1.0208e-01],\n",
      "          [-2.3528e-02, -1.0416e-01,  1.2176e-02],\n",
      "          [-1.4259e-01, -1.6601e-01,  1.5138e-01]],\n",
      "\n",
      "         [[-1.1674e-01, -6.3930e-02,  1.6302e-01],\n",
      "          [ 2.7837e-02,  2.2274e-01, -1.1427e-01],\n",
      "          [-4.0469e-02, -1.1211e-01, -1.1598e-01]],\n",
      "\n",
      "         [[-4.4693e-02,  1.9719e-01,  4.9013e-02],\n",
      "          [-2.5067e-02,  9.0325e-02,  6.5706e-02],\n",
      "          [-5.0800e-03, -9.5696e-02, -4.1607e-02]],\n",
      "\n",
      "         [[-4.9723e-02,  7.3814e-02,  1.0241e-01],\n",
      "          [ 2.0458e-01,  8.5648e-02,  1.5634e-01],\n",
      "          [-1.1102e-01, -1.1310e-01, -1.4638e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4001e-02, -1.2041e-01, -6.4976e-02],\n",
      "          [ 1.2055e-01, -3.8953e-02,  3.5563e-02],\n",
      "          [-7.4622e-02, -3.1362e-02, -1.4405e-01]],\n",
      "\n",
      "         [[-7.8961e-02, -1.8130e-01,  7.6388e-03],\n",
      "          [ 1.1069e-02, -6.7849e-02, -1.7297e-03],\n",
      "          [-2.2316e-01, -2.0974e-02, -1.4095e-01]],\n",
      "\n",
      "         [[ 1.7397e-02, -8.1802e-03,  3.3639e-02],\n",
      "          [ 2.8872e-02,  1.0541e-03, -2.1386e-01],\n",
      "          [-1.7038e-01, -2.0131e-01, -6.4632e-02]],\n",
      "\n",
      "         [[-1.2350e-01, -2.0478e-01, -6.6836e-02],\n",
      "          [-2.1369e-01,  1.5313e-02, -8.5220e-02],\n",
      "          [-1.0067e-01, -2.5516e-01, -1.0931e-01]]]], device='cuda:0')\n",
      "0.bias tensor([0.2423, 0.1300, 0.0404], device='cuda:0')\n",
      "decoder 2 after:\n",
      "0.weight tensor([[[[ 0.0942,  0.0406, -0.0243],\n",
      "          [-0.1178,  0.1160,  0.2865],\n",
      "          [-0.0431,  0.0379,  0.0180]],\n",
      "\n",
      "         [[-0.2269,  0.1833,  0.1092],\n",
      "          [ 0.0425,  0.0670,  0.0671],\n",
      "          [ 0.2857,  0.0408,  0.1771]],\n",
      "\n",
      "         [[ 0.0648,  0.1685,  0.1363],\n",
      "          [ 0.2307,  0.1244,  0.0096],\n",
      "          [ 0.2527,  0.1374,  0.2942]],\n",
      "\n",
      "         [[ 0.2052,  0.3184,  0.1625],\n",
      "          [ 0.2384,  0.2620,  0.0675],\n",
      "          [ 0.0403,  0.3140,  0.0926]]],\n",
      "\n",
      "\n",
      "        [[[-0.0899, -0.0818,  0.1021],\n",
      "          [-0.0235, -0.1042,  0.0122],\n",
      "          [-0.1426, -0.1660,  0.1514]],\n",
      "\n",
      "         [[-0.1167, -0.0639,  0.2300],\n",
      "          [ 0.0278,  0.2896, -0.1812],\n",
      "          [-0.0405, -0.1121, -0.1160]],\n",
      "\n",
      "         [[ 0.0223,  0.2642,  0.1160],\n",
      "          [ 0.0419,  0.1573,  0.1327],\n",
      "          [-0.0051, -0.0957, -0.0416]],\n",
      "\n",
      "         [[ 0.0173,  0.1408,  0.1694],\n",
      "          [ 0.2716,  0.1527,  0.2233],\n",
      "          [-0.1110, -0.1131, -0.1464]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0140, -0.1204, -0.0650],\n",
      "          [ 0.1205, -0.0390,  0.0356],\n",
      "          [-0.0746, -0.0314, -0.1441]],\n",
      "\n",
      "         [[-0.1460, -0.2483, -0.0594],\n",
      "          [-0.0559, -0.1349, -0.0687],\n",
      "          [-0.2902, -0.0880, -0.2080]],\n",
      "\n",
      "         [[-0.0496, -0.0752, -0.0334],\n",
      "          [-0.0381, -0.0660, -0.2809],\n",
      "          [-0.2374, -0.2683, -0.1316]],\n",
      "\n",
      "         [[-0.1905, -0.2718, -0.1338],\n",
      "          [-0.2807, -0.0517, -0.1522],\n",
      "          [-0.1677, -0.3222, -0.1763]]]], device='cuda:0')\n",
      "0.bias tensor([ 0.3093,  0.1970, -0.0266], device='cuda:0')\n",
      "decoder 2 end.\n"
     ]
    }
   ],
   "source": [
    "class ClassifyCatDog(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifyCatDog, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.encoder.append(nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, stride=1, padding=1))\n",
    "        self.encoder.append(nn.ReLU())\n",
    "        self.encoder.append(nn.MaxPool2d(8, 8))\n",
    "        self.encoder.append(nn.Conv2d(4, 4, 3, stride=1, padding=1))\n",
    "        self.encoder.append(nn.ReLU())\n",
    "        self.encoder.append(nn.MaxPool2d(8, 8))\n",
    "        # Decoder 1\n",
    "        self.decoder_1 = nn.ModuleList()\n",
    "        self.decoder_1.append(nn.Conv2d(4, 3, 3, stride=1, padding=1))\n",
    "        self.decoder_1.append(nn.ReLU())\n",
    "        self.decoder_1.append(nn.MaxPool2d(4, 4))\n",
    "        # Decoder 2\n",
    "        self.decoder_2 = nn.ModuleList()\n",
    "        self.decoder_2.append(nn.Conv2d(4, 3, 3, stride=1, padding=1))\n",
    "        self.decoder_2.append(nn.ReLU())\n",
    "        self.decoder_2.append(nn.MaxPool2d(4, 4))\n",
    "        # Classifier\n",
    "        self.classifier = nn.ModuleList()\n",
    "        self.classifier.append(nn.Linear(3*2*2, 4))\n",
    "        self.classifier.append(nn.ReLU())\n",
    "        self.classifier.append(nn.Linear(4, 2))\n",
    "    def forward(self, x, d_idx):\n",
    "        # n*512*512*3\n",
    "        # Encoder\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        # Decoder\n",
    "        if d_idx == 1:\n",
    "            for layer in self.decoder_1:\n",
    "                x = layer(x)\n",
    "        elif d_idx == 2:\n",
    "            for layer in self.decoder_2:\n",
    "                x = layer(x)\n",
    "        # Classifier\n",
    "        x = x.view(-1, 3*2*2)\n",
    "        for layer in self.classifier:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "discriminator = ClassifyCatDog()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator = discriminator.cuda()\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ec = optim.Adam(discriminator.encoder.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "optimizer_dc_1 = optim.Adam(discriminator.decoder_1.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "optimizer_dc_2 = optim.Adam(discriminator.decoder_2.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "optimizer_cl = optim.Adam(discriminator.classifier.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "optimizer_all = optim.Adam(discriminator.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "\n",
    "def printParam(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        print(name, param.data)\n",
    "\n",
    "for x_i, x in enumerate(dataloader):\n",
    "    imgs   = x['img']\n",
    "    labels = x['label']\n",
    "    imgs   = imgs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    y  = discriminator(imgs, x_i%2+1)\n",
    "    loss = criterion(y, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    print(loss)\n",
    "    if x_i%2+1 == 1:\n",
    "        print(\"decoder 1 pre:\")\n",
    "        printParam(discriminator.decoder_2)\n",
    "        optimizer_all.step()\n",
    "        optimizer_all.zero_grad()\n",
    "        print(\"decoder 1 after:\")\n",
    "        printParam(discriminator.decoder_2)\n",
    "        print(\"decoder 1 end.\")\n",
    "    else:\n",
    "        print(\"decoder 2 pre:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "        optimizer_all.step()\n",
    "        optimizer_all.zero_grad()\n",
    "        print(\"decoder 2 after:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "        print(\"decoder 2 end.\")\n",
    "    \n",
    "    optimizer_ec.step()\n",
    "    optimizer_ec.zero_grad()\n",
    "    \n",
    "    if x_i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f07e7932950>\n"
     ]
    }
   ],
   "source": [
    "print(discriminator.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for x_i, x in enumerate(dataloader):\n",
    "        if x_i%10==9:\n",
    "            print(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
