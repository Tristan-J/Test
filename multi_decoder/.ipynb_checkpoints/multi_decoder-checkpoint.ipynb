{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/cat-dog\"\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def flip_lr(x): \n",
    "# horizontal flip transformation\n",
    "    if random.random()>0.5:\n",
    "        x = np.fliplr(x).copy()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from skimage import io, img_as_float32\n",
    "import os\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, data_dir, is_train=False, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.data_dir = os.path.join(data_dir, \"train\")\n",
    "        else:\n",
    "            self.data_dir = os.path.join(data_dir, \"test\")\n",
    "        self.img_ids = os.listdir(self.data_dir)\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_p = os.path.join(self.data_dir, img_id)\n",
    "        img = img_as_float32(io.imread(img_p)).transpose((2,0,1))\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        out = {}\n",
    "        out['name'] = img_id\n",
    "        if self.is_train:\n",
    "            out['img'] = img\n",
    "            out['label'] = 0 if img_id.split(\"_\")[1]=='cat' else 1\n",
    "        else:\n",
    "            out['img'] = img\n",
    "            out['label'] = 0 if img_id.split(\"_\")[1]=='cat' else 1\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flickr_dog_000013.jpg', 'flickr_cat_000054.jpg', 'flickr_dog_000044.jpg', 'flickr_dog_000002.jpg']\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = CatDogDataset(data_dir, is_train=True, transform=flip_lr)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=True)\n",
    "for x_i, x in enumerate(dataloader):\n",
    "    print(x['name'])\n",
    "    print(x['label'])\n",
    "    print(x['img'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(0.8057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "decoder 1 0:\n",
      "0.weight tensor([[[[-0.1051,  0.1584,  0.0214],\n",
      "          [-0.0344,  0.1017,  0.1629],\n",
      "          [ 0.0131, -0.1128,  0.1452]],\n",
      "\n",
      "         [[-0.0218, -0.1395, -0.0552],\n",
      "          [-0.0219,  0.1536, -0.1387],\n",
      "          [ 0.1242, -0.0277,  0.0546]],\n",
      "\n",
      "         [[-0.0730, -0.1994,  0.1896],\n",
      "          [-0.0542, -0.0989, -0.0320],\n",
      "          [-0.0675,  0.0180, -0.1300]],\n",
      "\n",
      "         [[-0.0088,  0.0611,  0.2087],\n",
      "          [ 0.0054,  0.0527,  0.1134],\n",
      "          [-0.2596, -0.2417, -0.0826]]],\n",
      "\n",
      "\n",
      "        [[[-0.0318, -0.1031,  0.0638],\n",
      "          [ 0.0963, -0.1222, -0.1077],\n",
      "          [ 0.0555, -0.1407, -0.0565]],\n",
      "\n",
      "         [[ 0.0491, -0.0867,  0.1140],\n",
      "          [ 0.1107, -0.1234,  0.1190],\n",
      "          [-0.1128,  0.1495,  0.0830]],\n",
      "\n",
      "         [[ 0.1259, -0.0208, -0.1920],\n",
      "          [ 0.2220,  0.2317,  0.0898],\n",
      "          [-0.0436, -0.2050,  0.2264]],\n",
      "\n",
      "         [[-0.1584, -0.1843, -0.2312],\n",
      "          [ 0.0184,  0.2081,  0.2453],\n",
      "          [-0.0116,  0.0085,  0.1234]]],\n",
      "\n",
      "\n",
      "        [[[-0.0567, -0.1531, -0.1557],\n",
      "          [ 0.0372, -0.0496,  0.0736],\n",
      "          [-0.1271,  0.1617,  0.0549]],\n",
      "\n",
      "         [[-0.1467,  0.1252, -0.1188],\n",
      "          [ 0.1077,  0.1536, -0.1469],\n",
      "          [ 0.0189,  0.0401,  0.1394]],\n",
      "\n",
      "         [[ 0.1673, -0.0645,  0.2452],\n",
      "          [ 0.0222, -0.0175,  0.2534],\n",
      "          [ 0.2618, -0.0187,  0.1874]],\n",
      "\n",
      "         [[-0.1745,  0.0254, -0.0223],\n",
      "          [ 0.0665, -0.1897, -0.0623],\n",
      "          [ 0.0555, -0.1641,  0.0628]]]], device='cuda:0')\n",
      "0.bias tensor([-0.1177,  0.2361, -0.0910], device='cuda:0')\n",
      "decoder 1 1:\n",
      "0.weight tensor([[[[-0.1051,  0.1584,  0.0214],\n",
      "          [-0.0344,  0.1017,  0.1629],\n",
      "          [ 0.0131, -0.1128,  0.1452]],\n",
      "\n",
      "         [[-0.0218, -0.1395, -0.0552],\n",
      "          [-0.0219,  0.1536, -0.1387],\n",
      "          [ 0.1242, -0.0277,  0.0546]],\n",
      "\n",
      "         [[-0.1392, -0.2662,  0.2566],\n",
      "          [ 0.0126, -0.1659,  0.0350],\n",
      "          [-0.0675, -0.0490, -0.1300]],\n",
      "\n",
      "         [[ 0.0582,  0.1280,  0.2756],\n",
      "          [-0.0616, -0.0143,  0.1804],\n",
      "          [-0.3266, -0.3087, -0.0826]]],\n",
      "\n",
      "\n",
      "        [[[-0.0318, -0.1031,  0.0638],\n",
      "          [ 0.0963, -0.1222, -0.1077],\n",
      "          [ 0.0555, -0.1407, -0.0565]],\n",
      "\n",
      "         [[ 0.0491, -0.0867,  0.1140],\n",
      "          [ 0.1107, -0.1234,  0.1190],\n",
      "          [-0.1128,  0.1495,  0.0830]],\n",
      "\n",
      "         [[ 0.1921, -0.0878, -0.2579],\n",
      "          [ 0.2888,  0.2984,  0.1568],\n",
      "          [-0.1105, -0.2719,  0.2934]],\n",
      "\n",
      "         [[-0.2254, -0.2513, -0.2981],\n",
      "          [ 0.0854,  0.2751,  0.3123],\n",
      "          [ 0.0554,  0.0754,  0.1904]]],\n",
      "\n",
      "\n",
      "        [[[-0.0567, -0.1531, -0.1557],\n",
      "          [ 0.0372, -0.0496,  0.0736],\n",
      "          [-0.1271,  0.1617,  0.0549]],\n",
      "\n",
      "         [[-0.1467,  0.1252, -0.1188],\n",
      "          [ 0.1077,  0.1536, -0.1469],\n",
      "          [ 0.0189,  0.0401,  0.1394]],\n",
      "\n",
      "         [[ 0.2343, -0.1315,  0.3121],\n",
      "          [ 0.0892, -0.0845,  0.3204],\n",
      "          [ 0.3287, -0.0857,  0.2544]],\n",
      "\n",
      "         [[-0.2415, -0.0416,  0.0447],\n",
      "          [-0.0005, -0.2567,  0.0047],\n",
      "          [-0.0115, -0.2311,  0.1298]]]], device='cuda:0')\n",
      "0.bias tensor([-0.1847,  0.3031, -0.1580], device='cuda:0')\n",
      "decoder 1 2:\n",
      "0.weight tensor([[[[-0.1051,  0.1584,  0.0214],\n",
      "          [-0.0344,  0.1017,  0.1629],\n",
      "          [ 0.0131, -0.1128,  0.1452]],\n",
      "\n",
      "         [[-0.0218, -0.1395, -0.0552],\n",
      "          [-0.0219,  0.1536, -0.1387],\n",
      "          [ 0.1242, -0.0277,  0.0546]],\n",
      "\n",
      "         [[-0.1903, -0.3179,  0.3083],\n",
      "          [ 0.0643, -0.2177,  0.0868],\n",
      "          [-0.0675, -0.1008, -0.1300]],\n",
      "\n",
      "         [[ 0.1100,  0.1798,  0.3274],\n",
      "          [-0.1134, -0.0660,  0.2322],\n",
      "          [-0.3784, -0.3605, -0.0826]]],\n",
      "\n",
      "\n",
      "        [[[-0.0318, -0.1031,  0.0638],\n",
      "          [ 0.0963, -0.1222, -0.1077],\n",
      "          [ 0.0555, -0.1407, -0.0565]],\n",
      "\n",
      "         [[ 0.0491, -0.0867,  0.1140],\n",
      "          [ 0.1107, -0.1234,  0.1190],\n",
      "          [-0.1128,  0.1495,  0.0830]],\n",
      "\n",
      "         [[ 0.2432, -0.1395, -0.3087],\n",
      "          [ 0.3404,  0.3500,  0.2086],\n",
      "          [-0.1623, -0.3236,  0.3451]],\n",
      "\n",
      "         [[-0.2771, -0.3031, -0.3499],\n",
      "          [ 0.1371,  0.3269,  0.3641],\n",
      "          [ 0.1071,  0.1272,  0.2421]]],\n",
      "\n",
      "\n",
      "        [[[-0.0567, -0.1531, -0.1557],\n",
      "          [ 0.0372, -0.0496,  0.0736],\n",
      "          [-0.1271,  0.1617,  0.0549]],\n",
      "\n",
      "         [[-0.1467,  0.1252, -0.1188],\n",
      "          [ 0.1077,  0.1536, -0.1469],\n",
      "          [ 0.0189,  0.0401,  0.1394]],\n",
      "\n",
      "         [[ 0.2860, -0.1833,  0.3639],\n",
      "          [ 0.1410, -0.1363,  0.3722],\n",
      "          [ 0.3804, -0.1375,  0.3061]],\n",
      "\n",
      "         [[-0.2933, -0.0934,  0.0964],\n",
      "          [-0.0523, -0.3085,  0.0564],\n",
      "          [-0.0633, -0.2829,  0.1816]]]], device='cuda:0')\n",
      "0.bias tensor([-0.2365,  0.3549, -0.2098], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class ClassifyCatDog(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassifyCatDog, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.encoder.append(nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, stride=1, padding=1))\n",
    "        self.encoder.append(nn.ReLU())\n",
    "        self.encoder.append(nn.MaxPool2d(8, 8))\n",
    "        self.encoder.append(nn.Conv2d(4, 4, 3, stride=1, padding=1))\n",
    "        self.encoder.append(nn.ReLU())\n",
    "        self.encoder.append(nn.MaxPool2d(8, 8))\n",
    "        # Decoder 1\n",
    "        self.decoder_1 = nn.ModuleList()\n",
    "        self.decoder_1.append(nn.Conv2d(4, 3, 3, stride=1, padding=1))\n",
    "        self.decoder_1.append(nn.ReLU())\n",
    "        self.decoder_1.append(nn.MaxPool2d(4, 4))\n",
    "        # Decoder 2\n",
    "        self.decoder_2 = nn.ModuleList()\n",
    "        self.decoder_2.append(nn.Conv2d(4, 3, 3, stride=1, padding=1))\n",
    "        self.decoder_2.append(nn.ReLU())\n",
    "        self.decoder_2.append(nn.MaxPool2d(4, 4))\n",
    "        # Classifier\n",
    "        self.classifier = nn.ModuleList()\n",
    "        self.classifier.append(nn.Linear(3*2*2, 4))\n",
    "        self.classifier.append(nn.ReLU())\n",
    "        self.classifier.append(nn.Linear(4, 2))\n",
    "    def forward(self, x, d_idx):\n",
    "        # n*512*512*3\n",
    "        # Encoder\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        # Decoder\n",
    "        if d_idx == 1:\n",
    "            for layer in self.decoder_1:\n",
    "                x = layer(x)\n",
    "        elif d_idx == 2:\n",
    "            for layer in self.decoder_2:\n",
    "                x = layer(x)\n",
    "        # Classifier\n",
    "        x = x.view(-1, 3*2*2)\n",
    "        for layer in self.classifier:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "discriminator = ClassifyCatDog()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator = discriminator.cuda()\n",
    "\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_all = optim.Adam(discriminator.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "\n",
    "def printParam(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        print(name, param.data)\n",
    "\n",
    "for x_i, x in enumerate(dataloader):\n",
    "    imgs   = x['img']\n",
    "    labels = x['label']\n",
    "    imgs   = imgs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    y  = discriminator(imgs, x_i%2+1)\n",
    "    loss = criterion(y, labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    print(loss)\n",
    "    if x_i%2+1 == 1: # path go through decoder_1\n",
    "#         print(\"decoder 1 pre:\")\n",
    "#         printParam(discriminator.decoder_2)\n",
    "        optimizer_all.step()\n",
    "        optimizer_all.zero_grad()\n",
    "#         print(\"decoder 1 after:\")\n",
    "#         printParam(discriminator.decoder_2)\n",
    "    else: # path go through decoder_2\n",
    "        print(\"decoder 1 0:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "        optimizer_all.step()\n",
    "#         optimizer_all.zero_grad()\n",
    "        print(\"decoder 1 1:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "        optimizer_all.step()\n",
    "        optimizer_all.zero_grad()\n",
    "        print(\"decoder 1 2:\")\n",
    "        printParam(discriminator.decoder_1)\n",
    "    \n",
    "    optimizer_ec.step()\n",
    "    optimizer_ec.zero_grad()\n",
    "    \n",
    "    if x_i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7f1a26f59cd0>\n"
     ]
    }
   ],
   "source": [
    "print(discriminator.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n",
      "9\n",
      "19\n",
      "29\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for x_i, x in enumerate(dataloader):\n",
    "        if x_i%10==9:\n",
    "            print(x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
